# ğŸ§  Sentiment Analysis Using RNN Comparison

## ğŸ“„ Overview
This project compares multiple **Recurrent Neural Network (RNN)** architectures â€” including **Simple RNN, LSTM, and GRU** â€” for sentiment analysis on textual data.  
The goal is to evaluate their performance on classifying sentiments (positive, negative, or neutral) and analyze which model performs best under different configurations.

---

## ğŸš€ Features
- Preprocessing of text data (tokenization, padding, and embedding)
- Implementation of multiple deep learning models:
  - Simple RNN  
  - LSTM (Long Short-Term Memory)  
  - GRU (Gated Recurrent Unit)
- Comparison of model accuracy, loss, and F1-score
- Visualization of training and validation metrics
- PDF report summarizing results under `src/results/`

---

## ğŸ§° Technologies Used
- **Python 3.x**
- **TensorFlow / Keras**
- **NumPy, Pandas, Matplotlib, Seaborn**
- **Scikit-learn**

---

## ğŸ“Š Results Summary
The models were trained and evaluated on a labeled sentiment dataset.

| Model | Accuracy | Precision | Recall | F1 Score |
|--------|-----------|------------|---------|-----------|
| Simple RNN | xx% | xx | xx | xx |
| LSTM | xx% | xx | xx | xx |
| GRU | xx% | xx | xx | xx |

> Replace the `xx` with your actual metrics from `src/results/metrics`.

---

## ğŸ“ Project Structure
